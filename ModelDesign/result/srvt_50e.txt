device is -------------- cuda
IEGMNetSimple5a(
  (conv1): Sequential(
    (0): Conv2d(1, 2, kernel_size=(6, 1), stride=(2, 1))
    (1): ReLU(inplace=True)
    (2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): Sequential(
    (0): Conv2d(2, 3, kernel_size=(5, 1), stride=(2, 1))
    (1): ReLU(inplace=True)
    (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv3): Sequential(
    (0): Conv2d(3, 5, kernel_size=(4, 1), stride=(2, 1))
    (1): ReLU(inplace=True)
    (2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv4): Sequential(
    (0): Conv2d(5, 10, kernel_size=(4, 1), stride=(2, 1))
    (1): ReLU(inplace=True)
    (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv5): Sequential(
    (0): Conv2d(10, 10, kernel_size=(4, 1), stride=(2, 1))
    (1): ReLU(inplace=True)
    (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (linear): Linear(in_features=370, out_features=2, bias=True)
)
conv1.0.weight torch.Size([2, 1, 6, 1])
conv1.0.bias torch.Size([2])
conv1.2.weight torch.Size([2])
conv1.2.bias torch.Size([2])
conv2.0.weight torch.Size([3, 2, 5, 1])
conv2.0.bias torch.Size([3])
conv2.2.weight torch.Size([3])
conv2.2.bias torch.Size([3])
conv3.0.weight torch.Size([5, 3, 4, 1])
conv3.0.bias torch.Size([5])
conv3.2.weight torch.Size([5])
conv3.2.bias torch.Size([5])
conv4.0.weight torch.Size([10, 5, 4, 1])
conv4.0.bias torch.Size([10])
conv4.2.weight torch.Size([10])
conv4.2.bias torch.Size([10])
conv5.0.weight torch.Size([10, 10, 4, 1])
conv5.0.bias torch.Size([10])
conv5.2.weight torch.Size([10])
conv5.2.bias torch.Size([10])
linear.weight torch.Size([2, 370])
linear.bias torch.Size([2])
Training Dataset loading finish.
Start training
Epoch:  0
0.8714113389626056
Test || Loss:0.00020 Acc: 0.95285
        Precision: 1.92340 Recall: 1.89077 F1: 1.90695 FB: 1.89721 
Epoch:  1
0.9220747889022919
Test || Loss:0.00011 Acc: 0.97309
        Precision: 1.95479 Recall: 1.93766 F1: 1.94619 FB: 1.94106 
Epoch:  2
0.9272858866103739
Test || Loss:0.00021 Acc: 0.94919
        Precision: 1.91794 Recall: 1.88229 F1: 1.89995 FB: 1.88932 
Epoch:  3
0.9273823884197828
Test || Loss:0.00012 Acc: 0.97072
        Precision: 1.95101 Recall: 1.93217 F1: 1.94154 FB: 1.93591 
Epoch:  4
0.9296501809408927
Test || Loss:0.00224 Acc: 0.51518
        Precision: 1.43047 Recall: 1.14493 F1: 1.27187 FB: 1.19254 
Epoch:  5
0.9260796139927624
Test || Loss:0.00012 Acc: 0.97223
        Precision: 1.95341 Recall: 1.93566 F1: 1.94450 FB: 1.93919 
Epoch:  6
0.9318214716525934
Test || Loss:0.00013 Acc: 0.96921
        Precision: 1.94862 Recall: 1.92868 F1: 1.93860 FB: 1.93263 
Epoch:  7
0.9348612786489746
Test || Loss:0.00012 Acc: 0.96900
        Precision: 1.93894 Recall: 1.93466 F1: 1.93680 FB: 1.93551 
Epoch:  8
0.9353437876960193
Test || Loss:0.00014 Acc: 0.96857
        Precision: 1.94760 Recall: 1.92718 F1: 1.93733 FB: 1.93123 
Epoch:  9
0.9361158021712908
Test || Loss:0.00021 Acc: 0.95005
        Precision: 1.91922 Recall: 1.88429 F1: 1.90159 FB: 1.89117 
Epoch:  10
0.9345235223160434
Test || Loss:0.00010 Acc: 0.97589
        Precision: 1.95708 Recall: 1.94558 F1: 1.95131 FB: 1.94787 
Epoch:  11
0.9372255729794934
Test || Loss:0.00013 Acc: 0.96814
        Precision: 1.94692 Recall: 1.92618 F1: 1.93649 FB: 1.93030 
Epoch:  12
0.9372738238841978
Test || Loss:0.00014 Acc: 0.96792
        Precision: 1.94658 Recall: 1.92569 F1: 1.93607 FB: 1.92983 
Epoch:  13
0.9372738238841978
Test || Loss:0.00030 Acc: 0.92616
        Precision: 1.84706 Recall: 1.85976 F1: 1.85339 FB: 1.85721 
Epoch:  14
0.9361158021712908
Test || Loss:0.00013 Acc: 0.96943
        Precision: 1.94896 Recall: 1.92918 F1: 1.93902 FB: 1.93310 
Epoch:  15
0.9398311218335343
Test || Loss:0.00010 Acc: 0.97438
        Precision: 1.95609 Recall: 1.94113 F1: 1.94858 FB: 1.94410 
Epoch:  16
0.9366465621230398
Test || Loss:0.00011 Acc: 0.97395
        Precision: 1.95317 Recall: 1.94157 F1: 1.94735 FB: 1.94388 
Epoch:  17
0.9368878166465622
Test || Loss:0.00018 Acc: 0.95888
        Precision: 1.93253 Recall: 1.90474 F1: 1.91853 FB: 1.91023 
Epoch:  18
0.9381423401688782
Test || Loss:0.00010 Acc: 0.97460
        Precision: 1.95702 Recall: 1.94127 F1: 1.94911 FB: 1.94440 
Epoch:  19
0.9387213510253317
Test || Loss:0.00012 Acc: 0.97244
        Precision: 1.95376 Recall: 1.93616 F1: 1.94492 FB: 1.93965 
Epoch:  20
0.9400241254523523
Test || Loss:0.00012 Acc: 0.97137
        Precision: 1.95204 Recall: 1.93367 F1: 1.94281 FB: 1.93731 
Epoch:  21
0.9419059107358263
Test || Loss:0.00012 Acc: 0.97417
        Precision: 1.95171 Recall: 1.94339 F1: 1.94754 FB: 1.94505 
Epoch:  22
0.9406996381182147
Test || Loss:0.00013 Acc: 0.96878
        Precision: 1.94794 Recall: 1.92768 F1: 1.93776 FB: 1.93170 
Epoch:  23
0.9403618817852835
Test || Loss:0.00013 Acc: 0.96900
        Precision: 1.94828 Recall: 1.92818 F1: 1.93818 FB: 1.93217 
Epoch:  24
0.9433051869722557
Test || Loss:0.00009 Acc: 0.97761
        Precision: 1.96099 Recall: 1.94885 F1: 1.95490 FB: 1.95127 
Epoch:  25
0.9433534378769602
Test || Loss:0.00009 Acc: 0.97804
        Precision: 1.96261 Recall: 1.94925 F1: 1.95591 FB: 1.95191 
Epoch:  26
0.9367913148371532
Test || Loss:0.00009 Acc: 0.97783
        Precision: 1.96189 Recall: 1.94899 F1: 1.95542 FB: 1.95156 
Epoch:  27
0.9425814234016888
Test || Loss:0.00011 Acc: 0.97201
        Precision: 1.95307 Recall: 1.93516 F1: 1.94407 FB: 1.93872 
Epoch:  28
0.9434981905910735
Test || Loss:0.00012 Acc: 0.97201
        Precision: 1.95307 Recall: 1.93516 F1: 1.94407 FB: 1.93872 
Epoch:  29
0.9430156815440289
Test || Loss:0.00010 Acc: 0.97696
        Precision: 1.96105 Recall: 1.94663 F1: 1.95381 FB: 1.94950 
Epoch:  30
0.9458624849215923
Test || Loss:0.00012 Acc: 0.97266
        Precision: 1.95410 Recall: 1.93666 F1: 1.94534 FB: 1.94012 
Epoch:  31
0.9440289505428227
Test || Loss:0.00011 Acc: 0.97675
        Precision: 1.96070 Recall: 1.94613 F1: 1.95339 FB: 1.94903 
Epoch:  32
0.9419059107358263
Test || Loss:0.00009 Acc: 0.97783
        Precision: 1.96099 Recall: 1.94959 F1: 1.95527 FB: 1.95186 
Epoch:  33
0.9403618817852835
Test || Loss:0.00008 Acc: 0.98019
        Precision: 1.96316 Recall: 1.95639 F1: 1.95977 FB: 1.95774 
Epoch:  34
0.9420506634499397
Test || Loss:0.00013 Acc: 0.97051
        Precision: 1.95067 Recall: 1.93167 F1: 1.94112 FB: 1.93544 
Epoch:  35
0.9425814234016888
Test || Loss:0.00008 Acc: 0.97890
        Precision: 1.96421 Recall: 1.95112 F1: 1.95764 FB: 1.95373 
Epoch:  36
0.9419059107358263
Test || Loss:0.00013 Acc: 0.96814
        Precision: 1.94692 Recall: 1.92618 F1: 1.93649 FB: 1.93030 
Epoch:  37
0.9435946924004825
Test || Loss:0.00012 Acc: 0.97266
        Precision: 1.95410 Recall: 1.93666 F1: 1.94534 FB: 1.94012 
Epoch:  38
0.9413751507840772
Test || Loss:0.00009 Acc: 0.97653
        Precision: 1.95798 Recall: 1.94720 F1: 1.95257 FB: 1.94934 
Epoch:  39
0.9452834740651387
Test || Loss:0.00010 Acc: 0.97438
        Precision: 1.95687 Recall: 1.94065 F1: 1.94872 FB: 1.94387 
Epoch:  40
0.9405066344993969
Test || Loss:0.00011 Acc: 0.97309
        Precision: 1.95479 Recall: 1.93766 F1: 1.94619 FB: 1.94106 
Epoch:  41
0.9425331724969843
Test || Loss:0.00007 Acc: 0.98213
        Precision: 1.96800 Recall: 1.95968 F1: 1.96383 FB: 1.96134 
Epoch:  42
0.9405066344993969
Test || Loss:0.00013 Acc: 0.96706
        Precision: 1.94522 Recall: 1.92369 F1: 1.93440 FB: 1.92796 
Epoch:  43
0.9424366706875754
Test || Loss:0.00009 Acc: 0.97675
        Precision: 1.96070 Recall: 1.94613 F1: 1.95339 FB: 1.94903 
Epoch:  44
0.9492400482509047
Test || Loss:0.00011 Acc: 0.97589
        Precision: 1.95930 Recall: 1.94414 F1: 1.95169 FB: 1.94715 
Epoch:  45
0.9474547647768395
Test || Loss:0.00010 Acc: 0.97847
        Precision: 1.96350 Recall: 1.95012 F1: 1.95679 FB: 1.95279 
Epoch:  46
0.9465379975874547
Test || Loss:0.00013 Acc: 0.96900
        Precision: 1.93415 Recall: 1.94078 F1: 1.93746 FB: 1.93945 
Epoch:  47
0.9386731001206272
Test || Loss:0.00001 Acc: 0.99849
        Precision: 1.99723 Recall: 1.99663 F1: 1.99693 FB: 1.99675 
Epoch:  48
0.9512665862484921
Test || Loss:0.00006 Acc: 0.98730
        Precision: 1.97235 Recall: 1.97621 F1: 1.97428 FB: 1.97544 
Epoch:  49
0.9519420989143547
Test || Loss:0.00001 Acc: 0.99763
        Precision: 1.99454 Recall: 1.99583 F1: 1.99519 FB: 1.99558 
Best Fb: 1.9967492394152186
Finish training
SRVT TRAINING COMPLETE. TESTING NOW.
device is -------------- cuda:0
[[2639    1]
 [   6 1999]]
0.9984930032292788
              precision    recall  f1-score   support

          SR       1.00      1.00      1.00      2640
          VT       1.00      1.00      1.00      2005

   micro avg       1.00      1.00      1.00      4645
   macro avg       0.25      0.25      0.25      4645
weighted avg       1.00      1.00      1.00      4645

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 2, 623, 1]              14
              ReLU-2            [-1, 2, 623, 1]               0
       BatchNorm2d-3            [-1, 2, 623, 1]               4
            Conv2d-4            [-1, 3, 310, 1]              33
              ReLU-5            [-1, 3, 310, 1]               0
       BatchNorm2d-6            [-1, 3, 310, 1]               6
            Conv2d-7            [-1, 5, 154, 1]              65
              ReLU-8            [-1, 5, 154, 1]               0
       BatchNorm2d-9            [-1, 5, 154, 1]              10
           Conv2d-10            [-1, 10, 76, 1]             210
             ReLU-11            [-1, 10, 76, 1]               0
      BatchNorm2d-12            [-1, 10, 76, 1]              20
           Conv2d-13            [-1, 10, 37, 1]             410
             ReLU-14            [-1, 10, 37, 1]               0
      BatchNorm2d-15            [-1, 10, 37, 1]              20
           Linear-16                    [-1, 2]             742
================================================================
Total params: 1,534
Trainable params: 1,534
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.09
Params size (MB): 0.01
Estimated Total Size (MB): 0.10
----------------------------------------------------------------
